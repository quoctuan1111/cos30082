{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040cf1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_14780\\3569967904.py\", line 6, in <module>\n",
      "    import torch, torch.nn as nn, torch.optim as optim\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "d:\\study\\cos30082\\final_asm\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, random, numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "NB_DIR = Path.cwd()\n",
    "PROJ_ROOT = NB_DIR.parent\n",
    "DATA_DIR = PROJ_ROOT / \"data\"\n",
    "TRAIN_DIR = DATA_DIR / \"classification_data\" / \"train_data\"\n",
    "VAL_DIR   = DATA_DIR / \"classification_data\" / \"val_data\"\n",
    "MODEL_DIR = PROJ_ROOT / \"models\"\n",
    "\n",
    "print(\"Running on:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720814fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838caf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.transform = transform\n",
    "        self.id2imgs = {}\n",
    "        for person in sorted(os.listdir(root)):\n",
    "            pdir = os.path.join(root, person)\n",
    "            if not os.path.isdir(pdir): continue\n",
    "            imgs = list(Path(pdir).glob(\"*\"))\n",
    "            if len(imgs) >= 2:\n",
    "                self.id2imgs[person] = imgs\n",
    "        self.ids = list(self.id2imgs.keys())\n",
    "\n",
    "    def __len__(self):  # approximate\n",
    "        return len(self.ids) * 4\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_id = random.choice(self.ids)\n",
    "        pos_id = anchor_id\n",
    "        neg_id = random.choice([i for i in self.ids if i != anchor_id])\n",
    "\n",
    "        a, p = random.sample(self.id2imgs[anchor_id], 2)\n",
    "        n = random.choice(self.id2imgs[neg_id])\n",
    "\n",
    "        def load(path): return self.transform(Image.open(path).convert(\"RGB\"))\n",
    "        return load(a), load(p), load(n)\n",
    "\n",
    "triplet_ds = TripletFaceDataset(TRAIN_DIR, tf)\n",
    "triplet_loader = DataLoader(triplet_ds, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6078aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fine-tuned backbone weights\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "class TripletEmbed(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        feat_dim = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.backbone = backbone\n",
    "        self.embed = nn.Linear(feat_dim, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        e = nn.functional.normalize(self.embed(f))\n",
    "        return e\n",
    "\n",
    "EMB_DIM = 128\n",
    "model = TripletEmbed(emb_dim=EMB_DIM).to(DEVICE)\n",
    "\n",
    "# Load your fine-tuned checkpoint weights for backbone\n",
    "FINETUNED_PATH = MODEL_DIR / \"classifier_embed_resnet18_softmax_cpu.pt\"\n",
    "state = torch.load(FINETUNED_PATH, map_location=DEVICE)\n",
    "backbone_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state.items() if \"backbone.\" in k}\n",
    "model.backbone.load_state_dict(backbone_dict, strict=False)\n",
    "print(\"Loaded fine-tuned backbone weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59dfdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████████████████████████████████| 1000/1000 [26:40<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: triplet_loss=0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████████████████████████████████| 1000/1000 [25:18<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: triplet_loss=0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████████████████████████████████| 1000/1000 [25:03<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: triplet_loss=0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████████████████████████████████| 1000/1000 [24:29<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: triplet_loss=0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████████████████████████████████| 1000/1000 [23:53<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: triplet_loss=0.0161\n",
      "Saved triplet embedding model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def triplet_loss(a, p, n, margin=0.2):\n",
    "    d_ap = (a - p).pow(2).sum(1)\n",
    "    d_an = (a - n).pow(2).sum(1)\n",
    "    return torch.relu(d_ap - d_an + margin).mean()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for a, p, n in tqdm(triplet_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", ncols=90):\n",
    "        a, p, n = a.to(DEVICE), p.to(DEVICE), n.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        ea, ep, en = model(a), model(p), model(n)\n",
    "        loss = triplet_loss(ea, ep, en)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    avg = epoch_loss / len(triplet_loader)\n",
    "    print(f\"Epoch {epoch+1}: triplet_loss={avg:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_DIR / \"triplet_embed_resnet18_cpu.pt\")\n",
    "print(\"Saved triplet embedding model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
